---
title: "Análise Dados"
author: "Mori, Danilo"
date: "19/11/2022"
output: 
  html_document:
    toc: true
    toc_depth: 5
editor_options: 
  chunk_output_type: console
---

<style>
body {
text-align: justify}
</style>

```{r setup,include=FALSE}
knitr::opts_chunk$set(echo = FALSE,eval = FALSE,message = FALSE,warning = FALSE)
# pacotes
library(dagitty)
library(ggdag)
library(gratia)
library(sads)
library(doMC)
library(gridExtra)
library(ggplot2)
library(readr)
library(purrr)
library(stringr)
library(tidyr)
library(MuMIn)
library(AICcmodavg)
library(insight)
library(bbmle)
library(DHARMa)
library(mgcv)
library(lme4)
library(gamm4)
library(plyr)
library(dplyr)
# objetos
load("dados/Rdata/md_MNEE.Rdata")
polyK=3
source("source/nameModel.R")
# dados
# df_resultMNEE
df_resultMNEE <- read_csv("dados/csv/resultados_MN/MNEE/df_resultMNEE.csv")
# df_sim
df_sim <- read_csv("dados/df_simulacao.csv")
# df_ad
f_z <- function(x) (x-mean(x))/sd(x)
df_ad <- inner_join(x=distinct(select(df_resultMNEE,-(Ssd:Smax))),
                    y=distinct(select(df_sim,-tif.path)),
                    by=c("SiteCode","k"),multiple="all") |>
  # escolhi remover depois do ajuste, para obter um melhor ajuste e depois excluir os valores
  # filter(k > 0.20) |> # figuras 5 e 6 apêndice Efeito de Escala
  mutate(k_cont = round(k,2),
         k = factor(round(k,2),levels=round(k,2)[20:1]), 
         across(Ntotal:S_obs,log,.names="log_{.col}"),
         log_S.N = log_S_obs - log_Ntotal,
         across(c(p,k_cont,log_Ntotal:log_S.N),f_z,.names = "{.col}_z")) |>
  select(-c(nCongDTS,effort_ha, Ntotal:S_obs))
# df_newdata
df_newdat <- read_csv("dados/csv/df_newdataSADs.csv")
# df_newdat <- expand.grid(p_z = seq(min(df_ad$p_z),max(df_ad$p_z), length=150),
#                          k_cont_z = seq(min(df_ad$k_cont_z),max(df_ad$k_cont_z), length=150))
# df_newdat <- adply(df_newdat,1,.fun = \(x) cbind(x,distinct(select(df_ad,SiteCode,log_S_obs_z,log_Ntotal_z))))
# write_csv(df_newdat,"dados/csv/df_newdataSADs.csv")
```

# MNEE 

## mapas contemporaneos

### Gráficos Exploratórios

```{r fig 1 - GE congruencia MNEE por p e k}
l_p <- list()
df_plot <- df_ad 
# |> filter(k_cont>0.20)
l_p[[1]] <- df_plot |> 
  ggplot(aes(x=p,y=nCongKS)) +
  geom_point() +
  geom_smooth(method = "loess",se=F) +
  labs(title="a) p, proporção de cobertura vegetal (~k)",
       y="número de SADs réplicas congruentes") +
  theme_bw() +
  facet_wrap(~k,ncol=5)
l_p[[2]] <- df_plot |> 
  mutate(p_cut = cut(p,20)) |> 
  ggplot(aes(x=k_cont,y=nCongKS)) +
  geom_point(alpha=0.4) +
  geom_line(alpha=0.4,aes(group=SiteCode)) +
  geom_smooth(method = "loess",se=F) +
  labs(title="b) k, prop. propágulos até a vizinhança (~cut(p, 20))",
       y="número de SADs réplicas congruentes",
       x="k") +
  theme_bw() +
  scale_x_reverse() +
  facet_wrap(~p_cut,ncol=5)
p <- grid.arrange(grobs=l_p,ncol=1,top="Congruência de MNEE")
ggsave("apendices/analise_dados/figuras/fig1_cong_p_k.png",
       width = 10.2,
       height = 10.7,
       plot = p)
```
  
    
__Figura 1__ Congruência de SADs MNEE por: a) proporção de cobertura vegetal; e b) k, grau de limitação de dispersão.
  
    
```{r fig 2 - congruencia de MNEE por k_cont e sitio de amostragem}
df_plot <- df_ad |> 
  mutate(label = paste0(SiteCode,", p=",round(p,2))) |>
  arrange(p)  
# |> filter(k_cont>0.20)
df_plot$label <- factor(df_plot$label,levels = unique(df_plot$label))
df_plot |> 
  ggplot(aes(x=k_cont,y=nCongKS)) +
  geom_smooth(method = "loess",se=F) +
  geom_point() +
  # labs(title="b) k, prop. propágulos até a vizinhança (~cut(p, 20))",
  #      y="número de SADs réplicas congruentes",
  #      x="k") +
  theme_bw() +
  scale_x_reverse() +
  facet_wrap(~label,ncol=6)
ggsave("apendices/analise_dados/figuras/fig2_cong_k_SiteCode.png",
       width = 10,
       height = 17.7)
```

__Figura 2__ Congruência de SADs MNEE grau de limitação de dispersão e sítio de amostragem.

```{r fig 3 - congruência por logs de N e S}
df_plot <- df_ad |> 
  mutate(log_S.N = log_S_obs - log_Ntotal) 
# df_plot |> 
#   filter(log_S.N >= -3.75) |>
#   ggplot(aes(x=p,y=log_S.N)) +
#   geom_point() +
#   geom_smooth() +
#   labs(y="S / N")
# df_plot |> 
#   filter(log_S.N >= -3.75) |> 
#   ggplot(aes(x=log_S.N,y=nCongKS)) +
#   geom_point(aes(color=p)) +
#   geom_smooth(se=F) +
#   facet_wrap(~k,ncol = 5)
# df_plot |> 
#   ggplot(aes(x=p,y=log_Ntotal)) +
#   geom_point() +
#   geom_smooth()
# summary(lm(log_S.N ~ poly(p,1,raw = T), filter(df_plot,log_S.N >= -3.75)))
#
f_ggplot <- function(df){
  ggplot(df,aes(x=value,y=nCongKS)) +
  geom_point() +
  geom_smooth(se=F,method = "gam") +
  labs(x=unique(df$name),y="") +
  facet_wrap(~k_cont,ncol=5)
}
l_p <- dlply(pivot_longer(df_plot,log_Ntotal:log_S_obs),"name",f_ggplot)
grid.arrange(grobs=l_p,ncol=2,top="# SAD congruentes em função dos log de N e S")  
```

__Figura 3__ Congruência de SADs MNEE por: log do número de indivíduos (esquerda); e log do número de espécies por
  

 GLMM Binomial

#### Modelo Cheio

```{r selecao modelo cheio N S p k, echo=T,eval=T,cache=TRUE}
l_md <- list()
l_md[[1]] <- glmer(cbind(nCongKS,100-nCongKS) ~ 
                     log_Ntotal_z * log_S_obs_z * poly(k_cont_z,3,raw=TRUE) * poly(p_z,3,raw=TRUE) + 
                     (poly(k_cont_z,3,raw=TRUE)|SiteCode),
          data=df_ad, family = "binomial",
          control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e9)),na.action = "na.fail")
l_md[[2]] <- glmer(cbind(nCongKS,100-nCongKS) ~ 
                     log_Ntotal_z * log_S_obs_z * poly(k_cont_z,3,raw=TRUE) +
                     poly(p_z,3,raw=TRUE) * poly(k_cont_z,3,raw=TRUE) + 
                     (poly(k_cont_z,3,raw=TRUE)|SiteCode),
          data=df_ad, family = "binomial",
          control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e9)),na.action = "na.fail")
l_md[[3]] <- glmer(cbind(nCongKS,100-nCongKS) ~ 
                     log_Ntotal_z * log_S_obs_z +
                     poly(p_z,3,raw=TRUE) * poly(k_cont_z,3,raw=TRUE) + 
                     (poly(k_cont_z,3,raw=TRUE)|SiteCode),
          data=df_ad, family = "binomial",
          control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e9)),na.action = "na.fail")
l_md[[4]] <- glmer(cbind(nCongKS,100-nCongKS) ~ 
                     log_Ntotal_z + log_S_obs_z +
                     poly(p_z,3,raw=TRUE) * poly(k_cont_z,3,raw=TRUE) + 
                     (poly(k_cont_z,3,raw=TRUE)|SiteCode),
          data=df_ad, family = "binomial",
          control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e9)),na.action = "na.fail")
l_md[[5]] <- glmer(cbind(nCongKS,100-nCongKS) ~ 
                     poly(p_z,3,raw=TRUE) * poly(k_cont_z,3,raw=TRUE) + 
                     (poly(k_cont_z,3,raw=TRUE)|SiteCode),
          data=df_ad, family = "binomial",
          control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e9)),na.action = "na.fail")
names(l_md) <- c("N * S * k * p","N * S * k","N * S", "N + S","1")
(df_aictab <- AICctab(l_md,weights=T) |> as.data.frame())
md_MNEE <- l_md[[row.names(df_aictab)[1]]]
```

```{r resíduos quantilicos do modelo cheio mais plausivel}
p_plot <- DHARMa::simulateResiduals(md_MNEE,n=1000)
plot(p_plot)
```


__Figura 4__ Resíduos Quantílicos modelo cheio selecionado MNEE nCongKS

```{r opcoes de graf exprotarios dos coef da estr aleat, eval=TRUE}
df_ranef <- ranef(md_MNEE)$SiteCode 
df_ranef$SiteCode <- row.names(df_ranef)
row.names(df_ranef) <- NULL
df_p <- df_ranef |> 
  pivot_longer(-SiteCode) |> 
  inner_join(df_ad |> select(SiteCode,p) |> distinct(),by="SiteCode")
df_p |> 
  ggplot(aes(sample=value)) + 
  stat_qq(alpha=0.3) + stat_qq_line(alpha=0.3,col="red") +
  labs(title="qqnorm dos coef. por SiteCode") +
  facet_wrap(~name,scales="free",ncol=3)
df_p |>
  ggplot(aes(x=p,y=value)) +
  geom_hline(yintercept = 0,color="red") +
  geom_point() +
  geom_smooth() +
  facet_wrap(~name,ncol=2) +
  labs(title="Coef. por SiteCode ~ p") +
  theme_bw()
```

__Figura 5__ Resíduos Quantílicos modelo cheio selecionado MNEE nCongKS


```{r figura 6 observado e predito pelo modelo cheio de nCongKS MNEE, eval=T,fig.height=4}
# dados
df_md <- md_MNEE@frame
df_md$nCong_observado <- df_md$`cbind(nCongKS, 100 - nCongKS)`[,1]
df_md$nCong_predito <- predict(md_MNEE,type="response") * 100
# graficos
ggplot(df_md,aes(x=nCong_observado,y=nCong_predito)) +
  geom_smooth(method = "lm",aes(group=SiteCode),se=FALSE,alpha=0.3) +
  geom_abline(slope = 1,intercept = 0,col="red",alpha=0.8,size=2) +
  geom_point(alpha=0.3) +
  labs(x="nSADcong observado",
       y="nSADcong predito",
       title="Modelo Cheio",
       subtitle="predito ~ observado") +
  coord_cartesian(expand = F)
summary(lm(nCong_observado ~ nCong_predito,df_md))
```

__Figura 6__ Observado e predito pelo modelo cheio selecionado 


__Tabela 1__ Coeficiente de determinação marginal e condicional do modelo cheio selecionado para nCongKS de MNEE

```{r R2m e R2c do modelo cheio mais plausivel,cache=TRUE}
# md_MNEE <- glmer(cbind(nCongKS,100-nCongKS) ~ 
#                    log_Ntotal_z * log_S_obs_z *
#                    poly(p_z,polyK,raw=T) * poly(k_cont_z,polyK,raw=T) + 
#                    (poly(k_cont_z,polyK,raw=T)|SiteCode),
#           data=df_ad, family = "binomial",
#           control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e9)),na.action = "na.fail")
(df_R2_RE_MNEE <- MuMIn::r.squaredGLMM(md_MNEE))
# kableExtra::kable(df_R2_RE_MNEE)
```

##### Predito pelo modelo cheio para novo conjunto de dados

NOTA:
df_newdat é um data frame com a interpolação de p e k, e para cada par único de p e k há todos os sítios.

```{r bootstrap do modelo cheio mais plausível MNEE - df_newdat2,echo=T}
#new data
df_newdat2 <- df_newdat |> filter(SiteCode == "BAlenc4") |> select(p_z:SiteCode)
## Passo 2: crie as função que devem ser calculadas dos modelos a cada simulação
## Previstos por efeitos fixos e aleatórios
f1 <- function(.) predict(., newdata=df_newdat2)
## Previstos por efeitos fixos (argumento re.form=~0)
f2 <- function(.) predict(., newdata=df_newdat2, re.form=~0)
## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
b3 <- bootMer(md_MNEE, FUN = f1, nsim=1000, parallel="multicore", ncpus=2)
b4 <- bootMer(md_MNEE, FUN = f2, nsim=1000, parallel="multicore", ncpus=2)
## calcula as médias e intervalos de confiança quantílicos para cada combinação de preditoras
## no novo conjunto de dados
df_newdat2$mean <- apply(b3$t,2,mean)
df_newdat2$IC.low <- apply(b3$t,2,quantile, 0.025)
df_newdat2$IC.upp <- apply(b3$t,2,quantile, 0.975)
df_newdat2$mean.fixed <- apply(b4$t,2,mean)
df_newdat2$IC.low.fixed <- apply(b4$t,2,quantile, 0.025)
df_newdat2$IC.upp.fixed <- apply(b4$t,2,quantile, 0.975)
write_csv(x=df_newdat2,file = "dados/csv/resultados_MN/MNEE/df_newdata.csv")
```

```{r predito pelo modelo cheio para novo conjunto de dados - df_newdat,eval=T}
# função para summarizar 
f_summarise <- function(x,probs = c(0.05,0.25, 0.5, 0.75,0.95)){
  tibble(pred = unname(quantile(x,probs)),prob = probs)
}
#
df_newdat$pred <- predict(md_MNEE,newdata=df_newdat,type="response")
df_plot <- df_newdat |> 
  reframe(across(pred,f_summarise,.unpack=TRUE),.by=c(p_z,k_cont_z)) |> 
  rename_with(~str_remove(.,"pred_")) |> 
  mutate(label = paste0("Quant = ",prob),
         p = p_z*sd(df_ad$p) + mean(df_ad$p),
         k = k_cont_z*sd(df_ad$k_cont) + mean(df_ad$k_cont))
df_plot$label <- factor(df_plot$label,levels = unique(df_plot$label)[c(3,2,4,1,5)])
# gráficos
f_ggplot2 <- function(df,facets=2){
  ggplot(df,aes(x=p,y=k,fill=pred)) +
    geom_tile() +
    scale_fill_distiller(palette = "Spectral",limits=c(0,1)) +
    scale_y_reverse() +
    theme_classic() +
    coord_cartesian(expand = FALSE) +
    labs(fill="Pr(Cong)") +
    facet_wrap(~label,ncol = facets)
}
l_p <- list()
l_p[[1]] <- df_plot |> 
  filter(prob == 0.5) |> 
  f_ggplot2() + labs(x="")
l_p[[2]] <- df_plot |> 
  filter(prob != 0.5) |>
  f_ggplot2()
ggpubr::ggarrange(plotlist = l_p,nrow=2, common.legend = TRUE, legend="top")
```


#### Modelo Médio


```{r códigos para rodar o modelo médio,echo=T}
# todas as combinações de modelo do modelo cheio
registerDoMC(3)
l_md.dredge_MNEE <- llply(dredge(md_MNEE,trace = FALSE,evaluate=FALSE), eval,.parallel = TRUE)
# Model Averaging for SiteCode predictions
mdAvg_MNEE__MuMIn <- model.avg(l_md.dredge_MNEE)
# Model Averaging for new data predictions
mdAvg_MNEE__AICcmodavg <- modavgPred(l_md.dredge_MNEE,newdata = df_newdat,type="link") %>%
  cbind(df_pred)
# saves
save(l_md.dredge_MNEE,file="dados/Rdata/l_md.dredge_MNEE.Rdata") # lista c todas as combinações de modelo
save(mdAvg_MNEE__MuMIn,file="dados/Rdata/mdAvg_MNEE__MuMIn.Rdata") # predição do modelo médio para os dados observados
save(mdAvg_MNEE__AICcmodavg,file="dados/Rdata/mdAvg_MNEE__AICcmodavg.Rdata") # predição do modelo médio para novo conjunto de dados 
```

__tabela X__ Tabela de Seleção com os submodelos mais plausíveis. 

```{r head tabela dos submodelos do modelo cheio}
load("dados/Rdata/l_md.dredge_MNEE.Rdata")
df_AICctabMNEE <- model.sel(l_md.dredge_MNEE)
```


```{r  observado e predito modelo medio, comment=FALSE, message=FALSE,warning=FALSE,results="hide",fig.width=8, fig.height=30}
# Modelo Global
load(file="dados/Rdata/mdAvg_MNEE__MuMIn.Rdata")
# Predição
df_md <- df_ad |> 
  mutate(label=paste0(SiteCode,", p=",round(p,3)),
         pred_modCheio = predict(md_MNEE,type="response") * 100,
         pred_modMedio = predict(mdAvg_MNEE__MuMIn,type="response")*100) |> 
  arrange(p)
df_md$label <- factor(df_md$label,levels = unique(df_md$label))
v_cols <- c("md médio" = "red", "md cheio" = "blue")

(p <- df_md |> 
  # pivot_longer(pred_modCheio:pred_modMedio) |>
  ggplot(aes(x=k_cont,y=nCongKS)) +
  # geom_line(aes(y=pred_modCheio),color="blue") +
  geom_line(aes(y=pred_modMedio),color="red",alpha=0.4) +
  geom_point() +
  theme_bw() +
  scale_x_reverse() +
  labs(x="k",y="# SADs congruentes",title="Predito pelo modelo médio (azul) e cheio (vermelho) são iguais") +
  facet_wrap(~label,ncol=6))
ggsave("apendices/analise_dados/figuras/fig6b_PredObs_k_Site.png",p,
       width = 10,
       height = 17.7)

```


```{r comparacao modelo medio e modelo cheio para novo conjunto de dados - df_newdat2}
df_newdat2$pred_mdMedio <- predict(mdAvg_MNEE__MuMIn,type="response",newdata=df_newdat2)*100
df_newdat2$pred_mdCheio <- predict(md_MNEE,type="response",newdata=df_newdat2)*100
df_newdat2 |>
  mutate(p = p_z*sd(df_ad$p) + mean(df_ad$p),
         k = k_cont_z*sd(df_ad$k_cont) + mean(df_ad$k_cont)) |> 
  pivot_longer(starts_with("pred_")) |> 
  ggplot(aes(x=p,y=k,fill=value)) +
  geom_tile() +
  scale_fill_distiller(palette = "Spectral") +
  scale_y_reverse() +
  theme_classic() +
  facet_wrap(~name,ncol=2)
```

### GAMM

Objetivo:
Melhorar as estatísticas resumo em função de p e k.

```{r descrição apenas em função de modelos que consideram p e k}

```


#### DAG:

```{r DAG MNEE contemp - PrCong N S k p prox Sesp Desp}
l_coord <- list(
  x = c(PrCong = 0, Sobs = 0, N = 2, p = 3, k = 4, Sesp = 0, effort = 2, PERTesp = 3.5, Prox = 2),
  y = c(PrCong = 0, Sobs = 2, N = 2, p = 1.5, k=0.5, Sesp = 6, effort = 4, PERTesp = 6, Prox = 7)
)
dag_PrCong <- dagify(PrCong ~ p + k + Sobs + N,
                     Sesp ~ Prox + PERTesp,
                     PERTesp ~ Prox,
                     effort ~ Prox + Sesp + PERTesp,
                     Sobs ~ Sesp + effort + N,
                     N ~ effort,
                     p ~ PERTesp,
                     labels = c(
                       "PrCong" = "Pr(Cong)",
                       "p" = "p",
                       "k" = "k",
                       "N" = "N",
                       "Sobs" = "S obs",
                       "Sesp" = "S esp",
                       "PERTesp" = "Pert. esp",
                       "Prox" = "Prox. centros",
                       "effort" = "effort"
                     ),
                     outcome = "PrCong",
                     latent = c("Sesp","PERTesp","Prox"),
                     exposure = c("p","k"),
                     coords = l_coord) 
l_p <- list()
l_p[[1]] <- ggdag(dag_PrCong,text = FALSE, use_labels = "label") +
  theme_void()# 
ggdag_paths(dag_PrCong)
ggdag_adjustment_set(dag_PrCong,shadow = TRUE,text = FALSE, use_labels = "label") +
  theme_dag_gray() +
  scale_color_manual(values=c("red4","green4"))
  # ggpmisc::geom_table_npc(data=df_text.table,aes(npcx = x, npcy = y, label = data)) +
```



Parametrização adequada segundo Gavin Simpson em vídeo do Ecological Forecasting:

A lógica de parametrização é:
i) deixar k grande suficiente
ii) pois a penalização do overfitting é ajustada. 

Melhor mesmo é usar REML que já considera isso. Mas sempre fazer o k.check

Ideia geral dos GAMMs:

a) existem duas variáveis que sempre estão relacionadas com a exposição da árvore genealógica da comunidade local ao pool de indivíduos da paisagem ao redor: número de indivíduos (N) e número de espécies (S), pois eles determinam o número de linhagens inicial e final nas simulações coalescentes.
b) Nas simulações com grau de limitação de dispersão (MNEE e MNEI) outra variável relacionada com a exposição é k.
c) Uma expectativa é que quanto maior o grau de exposição da árvore genealógica, maior deve ser ser a possível influência da configuração espacial no chuva de propágulos do pool de indivíduos remanescente na paisagem. A restrição da chuva de propágulos pela perda de habitat aumenta com a redução da proporção de cobertura vegetal. Então p está modelando a chuva de propágulos máxima possível. 

Sobre t2():
If full = TRUE then there is a separate penalty for each combination of null space column and range space. This gives strict invariance. If FALSE each combination of null space and range space generates one penalty, but the coulmns of each null space basis are treated as one group. The latter is more parsimonious, but does mean that invariance is only achieved by an arbitrary rescaling of null space basis vectors.

```{r gamm MNEE contemporaneo}
df_md <- df_ad |> 
  mutate(SiteCode = factor(SiteCode))
l_md <- list() 
l_md[[1]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(log_Ntotal_z,log_S_obs_z) + ti(log_Ntotal_z,log_S_obs_z,k_cont_z) +
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[2]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(log_Ntotal_z,log_S_obs_z) + 
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[3]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[4]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[5]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(log_Ntotal_z,k_cont_z) +
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[6]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(log_S_obs_z,k_cont_z) +
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[7]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(log_Ntotal_z,k_cont_z) + ti(log_S_obs_z,k_cont_z) +
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[8]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(log_Ntotal_z,log_S_obs_z) + ti(log_Ntotal_z,k_cont_z) + ti(log_S_obs_z,k_cont_z) +  
                   ti(log_Ntotal_z,log_S_obs_z,k_cont_z) +
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[9]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   ti(log_Ntotal_z,log_S_obs_z) + ti(log_Ntotal_z,k_cont_z) + ti(log_S_obs_z,k_cont_z) +  
                   ti(k_cont_z,p_z) +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[10]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[11]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(k_cont_z,bs = "cr") + s(p_z,bs = "cr") +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[12]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_S_obs_z,bs = "cr") + s(k_cont_z,bs = "cr") +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
l_md[[13]] <- gam(cbind(nCongKS,100-nCongKS)  ~ 
                   s(log_Ntotal_z,bs = "cr") + s(k_cont_z,bs = "cr") +
                   s(k_cont_z, SiteCode, bs="fs",xt=list(bs="cr")) + 
                   s(SiteCode,bs="re"),
                 data = df_md, family="binomial", method = "REML")
names(l_md) <- c("s(N,S,k,p) + ti(N,S) + ti(N,S,k) + ti(p,k)",
                 "s(N,S,k,p) + ti(N,S) + ti(p,k)",
                 "s(N,S,k,p) + ti(p,k)",
                 "s(k,p) + ti(p,k)",
                 "s(N,k,p) + ti(N,k) + ti(p,k)",
                 "s(S,k,p) + ti(S,k) + ti(p,k)",
                 "s(N,S,k,p) + ti(N,k) + ti(S,k) + ti(p,k)",
                 "s(N,S,k,p) + ti(N,S) + ti(N,k) + ti(S,k) + ti(N,S,k) + ti(p,k)",
                 "s(N,S,k,p) + ti(N,S) + ti(N,k) + ti(S,k) + ti(p,k)",
                 "s(N,S,k,p)",
                 "s(k,p)",
                 "s(S,k)",
                 "s(N,k)")
l_md_GAMM <- l_md
save(l_md_GAMM,file="dados/Rdata/l_md_GAMM.Rdata")
```
```{r}
load("dados/Rdata/l_md_GAMM.Rdata")
l_md <- l_md_GAMM[c(1:3,7:10)]
(df_aicctab <- AICctab(l_md,weights=TRUE) |> as.data.frame())
```


__Qual a melhor forma de descrever as preditoras em função de si mesmas?__

```{r melhor forma de descrever as preditoras}
df_md0 <- df_md |> filter(k=="0.99") # remove valores repetidos pelos graus de limitação de dispersão simulados
l_md <- list()
l_md[[1]] <- gam(log_Ntotal_z ~ s(p_z,bs="cr"),data = df_md0)
l_md[[2]] <- gam(log_S_obs_z ~ s(p_z,bs="cr"),data = df_md0)
l_md[[3]] <- gam(log_Ntotal_z ~ s(log_S_obs_z,bs="cr"),data = df_md0)
l_md[[4]] <- gam(log_S_obs_z ~ s(log_Ntotal_z,bs="cr"),data = df_md0)
l_md[[5]] <- gam(log_Ntotal_z ~ s(p_z,bs="cr") + s(log_S_obs_z,bs="cr"),data = df_md0)
l_md[[6]] <- gam(log_S_obs_z ~ s(p_z,bs="cr") + s(log_Ntotal_z,bs="cr"),data = df_md0)
l_md[[7]] <- gam(p_z ~ s(log_Ntotal_z,bs="cr"),data = df_md0)
l_md[[8]] <- gam(p_z ~ s(log_Ntotal_z,bs="cr") + s(log_S_obs_z,bs="cr"),data = df_md0)
l_md[[9]] <- gam(p_z ~ s(log_S_obs_z,bs="cr"),data = df_md0)
names(l_md) <- c("N ~ p", "S ~ p", "N ~ S", "S ~ N","N ~ p,S", "S ~ p,N",
                 "p ~ N", "p ~ S + N", "p ~ S")
l <- l_md[c(1,3,5)]
AICctab(l,weights=T)
l <- l_md[c(2,4,6)]
AICctab(l,weights=T)
l <- l_md[c(7:9)]
AICctab(l,weights=T)
```



#### avaliação concurvidade

Concurvidade ocorre quando uma variável preditora pode ser bem descrita por um smooth de uma outra variável preditora (Wood 2016? Checking and Selecting GAMs). Nessa sequência de slide ele exemplifica:
- consider a model containing smooths f1 and f2.
- we can decompose f2 = f12 + f22; f12: the part of f2 representable in the space of f1, while f22 is the remaining component, which lies exlusively in the space of f2.
- a measure of concurvity is \alpha = (||f12||^2 )/(||f2||^2 ), leading to 3 estimates:

1) alpha
2) the maximum value that alpha could take for any estimates, using the given bases for f1 and f2.
3) the ratio of the size of the basis for f12 relative to the basis for f2, using some matrix norm.

1,2,3 respectivamente, observed, worst, estimated 

para a função concurvidade:
full = FALSE: comparação em pares; TRUE: comparação de cada termo com o resto do

Avaliação de concurvidade para o modelo cheio:

O gráfico de efeitos parciais indica que o modelo não conseguiu distinguir os smoother para log(N) e log(S), indicando a existência de concurvidade entre essas duas variáveis: essas preditoras podem ser bem descrita por um smooth uma da outra. A concurvidade pode ser compreendidada como uma extensão da colinearidade em modelos lineares. Na prática o modelo não consegue distinguir os efeitos de log(N) e log(S) um do outro e um novo conjunto de dados que considera a variação ortogonal de log(N) e log(S) deve apresentar predições ruins. Assim, o novo conjunto de dados irá conservar a covariação de log(N) e log(S) ao pressupor que todos os sítios observados (ao longo do gradiente de p) irão se repetir para cada combinação de p e k. 


__modelo mais plausível__ Pr(Cong) ~ f(S,p,k,SiteCode)

```{r}
gamm_MNEE <- l_md[[row.names(df_aicctab)[1]]]
k.check(gamm_MNEE)
gratia::appraise(gamm_MNEE)
summary(gamm_MNEE)
gratia::draw(gamm_MNEE)
(df_conc <- concurvity(gamm_MNEE,full=FALSE)$observed |> as.data.frame())
```

O alpha do smoother de log(S) em relação ao smoother p é de ~0.36; e a relação inversa é de ~0.23. Os outros alphas são pequenos (NOTA: olhar o motivo dos smoothers da estrutura aleatória ficarem igual a 1 para todos os outros smoother da estrutura fixa, penso que isso pode estar relacionado com a forma que é feito a regressão dos smoothers aleatórios para os fixos e vice-versa). 

A avaliação de concurvidade e os efeitos parciais são coerentes: o modelo distingue mais o efeito de log(S) em relação ao efeito de p; porém ambos apresentam influência da concurvidade na estimativa dos smoothers. 

Entendo que apesar desse modelo ser o mais plausível ele pode não ser muito útil, pois interpolar os valores de p é essencial para compreender as expectativas teóricas.

__2o modelo mais plausível__ Pr(Cong) ~ f(p,k,SiteCode)

```{r}
gamm_MNEE <- l_md[[row.names(df_aicctab)[2]]]
k.check(gamm_MNEE)
gratia::appraise(gamm_MNEE)
# summary(gamm_MNEE)
gratia::draw(gamm_MNEE)
(df_conc <- concurvity(gamm_MNEE,full=FALSE)$observed |> as.data.frame())
```

O segundo modelos mais plausível parece não conseguir estimar um smoother adequado para p, pois o smoother conta com cerca de 1 grau de liberdade, indicando que o smoother tende a uma reta, apesar de ter iniciado com 9 funções base.
Os efeitos parciais de p apresentam elevado erro padrão ao redor da estimativa de efeito parcial que tende a uma reta, indicando que há muita mais informação associada com Pr(Cong) e p do que o smoother consegue estimar. Apesar desse modelo ser útil por considerar apenas as variáveis preditoras relacionadas com a expectativa teórica da ecologia da paisagem, ele faz uma estimativa ruim do smoother de p.

__3o modelo mais plausível__ ~ s(M,S,k,p) + ti(p,k)

```{r}
(gamm_MNEE <- l_md[[row.names(df_aicctab)[3]]])
k.check(gamm_MNEE)
gratia::appraise(gamm_MNEE)
# summary(gamm_MNEE)
gratia::draw(gamm_MNEE)
(df_conc <- concurvity(gamm_MNEE,full=FALSE)$observed |> as.data.frame())
```

Esse modelo apresenta problemas de concurvidade. As preditoras N, p e S não tem smoother estimados de forma adequadas, pois os efeitos parciais dos smoothers individuais apresentam graus de liberdade próximo de 1, tendendo a uma reta, com erro-padrão elevado e que varia ao longo do gradiente da preditora. Esse modelo possui pouco peso de evidência e não deve ser útil para avaliar as expectativas teóricas.

__4o modelo mais plausível__ modelo cheio

```{r}
(gamm_MNEE <- l_md[[row.names(df_aicctab)[4]]])
k.check(gamm_MNEE)
gratia::appraise(gamm_MNEE)
# summary(gamm_MNEE)
gratia::draw(gamm_MNEE)
df_conc <- concurvity(gamm_MNEE,full=FALSE)$observed |> as_tibble() |> as.data.frame()
rownames(df_conc) <- names(df_conc)
select(df_conc[2:8,],-c(para,`s(k_cont_z,SiteCode)`,`s(SiteCode)`))
```

No quarto modelo mais plausível, o modelo cheio, que soma cerca de 4% do peso de evidência, há problemas de concurvidade principalmente associado às variáveis log(S) e log(N). Os graus de liberdade do smoother individual de p é o dobro do observado nos GAMMs mais plausíveis e a incerteza varia menos ao longo do gradiente da preditora. Jà os smoothers dos log de N e S apresentam graus de liberdade próximos de 1, principalmente do log(N), e apresentam incerteza elevada e que varia ao longo do gradiente das variáveis. 

Os alphas do teste concurvidade apresentam indicação de concurvidade nos smoothers indivíduos de p, N e S. 
O smoother de log(N) tem alpha de 22.92% para o smoother de log(S), 11.34% para o de p e 71.24% para o tensor entre log(S) e log(N). 
O smoother de log(S) tem alpha de 12.10% para o smoother de log(N), 4% para o smoother de p e 95% com o tensor de log(N) e log(S)
O smoother de p tem alpha de 10% para o smoother de log(N), de 16.9% para o smoother de log(S) e de 21% para o tensor de log(N) e log(S).
O tensor de log(N) e log(S) possui alpha de 18% com o smoothe de log(N), 68% com o smoother de log(S) e 9% com o smoother de p
O tensor de log(N), log(S) e k possui lapha de 1,7% com o tensor de k e p
o tensor de k e p possui alpha de 1.2% com o tensor triplo.

__5o modelo mais plausível__

```{r}
(gamm_MNEE <- l_md_GAMM[[row.names(df_aicctab)[5]]])
k.check(gamm_MNEE)
gratia::appraise(gamm_MNEE)
# summary(gamm_MNEE)
gratia::draw(gamm_MNEE)
df_conc <- concurvity(gamm_MNEE,full=FALSE)$observed |> as_tibble() |> as.data.frame()
rownames(df_conc) <- names(df_conc)
```

O modelo tem dificuldade de distinguir os efeitos parciais de p, log(S) e log(N). 

PEcabo2 (log_Ntotal_z ~ 0)
SPpesmF (log_S_obs_z ~ 0)


#### predição

ESTRATÉGIA:

Contrafactual gráfico: Como seria Pr(Cong) caso log(N) e log(S) permanecem em seus valores médios e a variação entre sítios fossem desconsiderada? Ou seja, quais os efeitos de p e k em isolamento?





__Como construir o novo conjunto de dados?__




```{r predição para novo conjunto de dados md_GAMM}

# 
# lapply(l_md,summary)

df_newdat2 <- df_newdat |> filter(SiteCode == "BAlenc4") |> select(p_z:SiteCode) |> 
  mutate()
df_plotGAMM <- df_newdat2
df_plotGAMM$pred <- predict.gam(gamm_MNEE,newdata = df_plotGAMM,type="response")
df_plotGAMM <- df_plotGAMM |> 
  # reframe(across(pred,f_summarise,.unpack=TRUE),.by=c(p_z,k_cont_z)) |> 
  # rename_with(~str_remove(.,"pred_")) |> 
  mutate(
# label = paste0("Quant = ",prob),
         p = p_z*sd(df_ad$p) + mean(df_ad$p),
         k = k_cont_z*sd(df_ad$k_cont) + mean(df_ad$k_cont))
# df_plotGAMM$label <- factor(df_plotGAMM$label,levels = unique(df_plotGAMM$label)[c(3,2,4,1,5)])
df_plotGAMM$label <- "predito novo conjunto de dados"
# gráficos
f_ggplot2 <- function(df,facets=2){
  ggplot(df,aes(x=p,y=k,fill=pred)) +
    geom_tile() +
    scale_fill_distiller(palette = "Spectral",limits=c(0,1)) +
    scale_y_reverse() +
    theme_classic() +
    coord_cartesian(expand = FALSE) +
    labs(fill="Pr(Cong)") +
    facet_wrap(~label,ncol = facets)
}
l_p <- list()
l_p[[1]] <- df_plotGAMM |> 
  # filter(prob == 0.5) |> 
  f_ggplot2() + labs(x="")
l_p[[2]] <- df_plotGAMM |> 
  filter(prob != 0.5) |>
  f_ggplot2()
ggpubr::ggarrange(plotlist = l_p,nrow=2, common.legend = TRUE, legend="top")
```

```{r}
df_md$pred <- predict(gamm_MNEE,type="response") * 100
df_md <- df_md |> 
  mutate(label=paste0(SiteCode,", p=",round(p,3))) |> 
  arrange(p)
df_md$label <- factor(df_md$label,levels = unique(df_md$label))
(p <- df_md |> 
  # pivot_longer(pred_modCheio:pred_modMedio) |>
  ggplot(aes(x=k_cont,y=nCongKS)) +
  # geom_line(aes(y=pred_modCheio),color="blue") +
  geom_line(aes(y=pred),color="red",alpha=0.4) +
  geom_point() +
  theme_bw() +
  scale_x_reverse() +
  labs(x="k",y="# SADs congruentes",title="Predito pelo modelo médio (azul) e cheio (vermelho) são iguais") +
  facet_wrap(~label,ncol=6))
ggsave("apendices/analise_dados/figuras/gammMNEE_PredObs_k_Site.png",p,
       width = 10,
       height = 17.7)

```

