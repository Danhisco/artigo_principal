---
title: "Apêndice 2: Support Information"
author: "Mori, Danilo"
date: "19/11/2022"
output: 
  bookdown::pdf_document2:
    latex_engine: xelatex
    fig_caption: yes
  bookdown::html_document2:
    toc: true
    toc_depth: 5
    fig_caption: yes
editor_options: 
  chunk_output_type: console
---

<style>
body {
text-align: justify}
</style>

```{r setup,include=FALSE}
knitr::opts_chunk$set(echo = FALSE,eval = TRUE,message = FALSE,warning = FALSE,cache=TRUE)
# pacotes
library(dagitty)
library(ggdag)
library(gt)
library(gratia)
library(sads)
library(doMC)
library(metR)
library(gridExtra)
library(ggplot2)
library(readr)
library(purrr)
library(stringr)
library(tidyr)
library(MuMIn)
library(AICcmodavg)
library(insight)
library(bbmle)
library(DHARMa)
library(mgcv)
library(lme4)
library(data.table)
library(plyr)
library(dplyr)
source("source/nameModel.R")
source("source/GAMMtools.R")
# dados
# df_dados_disponiveis
df_dados_disponiveis <- read_csv(file = "dados/df_dados_disponiveis.csv")
# df_p
df_p <- read_csv("dados/df_p.csv")
# df_resultMNEE
df_resultados <- read_csv("dados/csv/resultados_MN/df_resultados.csv")
# df_sim
df_sim <- read_csv("dados/df_simulacao.csv")
# df_Urep
df_Urep <- list.files(path = "dados/csv/taxaU/MNEE", pattern = ".csv",recursive = T,full.names = T) %>%  
  adply(.,1,data.table::fread,.id=NULL) %>% na.omit()
# df_U
df_U <- fread("dados/csv/taxaU/df_U.csv")
# df_contrastes
df_contrastes <- fread("dados/csv/taxaU/df_contrastes.csv")
# df_ad: dados completos, com todos os logOR e as proporções observadas para os 3 e as preditoras
f_z <- function(x) (x-mean(x))/sd(x)
df_ad <- df_resultados |>
  arrange(p) |> 
  inner_join(distinct(select(df_sim,SiteCode,Ntotal:S_obs)),"SiteCode") |> 
  mutate(diffS = (Smed - S_obs)/S_obs)
# df_contrastes: contrastes por sítio e grau de limitação de dispersão
df_contrastes <- fread(file="dados/csv/taxaU/df_contrastes.csv") |> 
  inner_join(df_sim |> select(SiteCode,Ntotal:S_obs) |> distinct(),
             by="SiteCode") |> 
  rename(N=Ntotal,S=S_obs) |> 
  mutate(across(N:S,log,.names="log.{.col}"),
         across(c(p,k,log.N:log.S),f_z,.names = "{.col}_z"),
         SiteCode = factor(SiteCode)) |> 
  select(-c(N:log.S))
# df_md: dados necessários 
df_md <- df_ad |> 
  inner_join(df_contrastes |> 
               select(SiteCode:efeito_conf) |> 
               mutate(across(.cols=c(p,k,contains("efeito")),f_z,.names="{.col}_z")) |> 
               select(-c(p,efeito_area:efeito_conf)) |> 
               pivot_longer(starts_with("efeito_"),names_to="logOR_pair",values_to="contraste_z") |> 
               mutate(logOR_pair = case_when(logOR_pair == "efeito_area_z" ~ "non_frag.ideal",
                                             logOR_pair == "efeito_frag_z" ~ "cont.non_frag",
                                             TRUE ~ "cont.ideal")),
             by=c("SiteCode","k","logOR_pair")) |> 
  mutate(SiteCode = factor(SiteCode),
         land_hyp = factor(land_type),
         contrasteSAD_z = f(logOR_value)) |> 
  select(-land_type) |> 
  rename(nCong=nCongKS)
  # df_newdata
fwrite(df_md,"dados/csv/df_md_logOR.csv")
df_newpred <- fread(file="dados/csv/df_newpred.csv") |> 
  select(-starts_with("log_"))
# df_pred
# df_pred <- read_csv("dados/csv/resultados_MN/MNEE/df_pred.csv")
# df_newdat <- expand.grid(p_z = seq(min(df_ad$p_z),max(df_ad$p_z), length=150),
#                          k_cont_z = seq(min(df_ad$k_cont_z),max(df_ad$k_cont_z), length=150))
# df_newdat <- adply(df_newdat,1,.fun = \(x) cbind(x,distinct(select(df_ad,SiteCode,log_S_obs_z,log_Ntotal_z))))
# write_csv(df_newdat,"dados/csv/df_newdataSADs.csv")
#
# df_intePred_contrastes.csv
df_intPred <- fread("dados/csv/df_intePred_contrastes.csv")
# df_congContrastetsREP.cvs
df_congContrastes <- fread("dados/csv/resultados_MN/df_congContrastes.csv") |> 
  inner_join(df_md |> 
               select(SiteCode,p,k,logOR_pair,contraste_z),
             by=c("SiteCode","k","pair" = "logOR_pair")) |> 
  arrange(p) |> 
  relocate(p,.after=k) |> 
  mutate(SiteCode = factor(SiteCode))
# loads
# load("dados/Rdata/l_md.contrastes.Rdata")
# load("dados/Rdata/md_frag_area.Rdata")
# load("dados/Rdata/l_md_congContrastes.Rdata")
# load("dados/Rdata/l_md_PrCong.Rdata")
df_plot <- df_md |> select(SiteCode:nCong,p_z:k_z) |> 
  inner_join(df_p) |> 
  inner_join(df_dados_disponiveis |> 
               filter(forest_succession != "capoeira") %>% 
               select(SiteCode, forest_succession)) %>% 
  arrange(p) |> 
  mutate(succession = case_when(forest_succession == "primary" ~ "1°",
                                forest_succession == "secondary" ~ "2°",
                                forest_succession == "primary/secondary" ~ "1.5°"),
         label = paste0(SiteCode,", p=",round(p,2)," ,suc=",succession),
         k_f=factor(round(k,2))) %>% 
  select(-succession)
df_plot$label <- factor(df_plot$label,levels=unique(df_plot$label))

```

```{r trackdown chunk, include=FALSE,eval=FALSE}
# pacotes
library(trackdown)
# both overwrite: 
# overwrite the current google drive file with the current Rmd:
# upload_file(file ="apendices/A2_figuras_tabelas/A2_figuras_tabelas.Rmd",
#             gpath = "mestrado/artigo_principal/apendices/",
#             hide_code = TRUE)
update_file(file ="apendices/A2_figuras_tabelas/A2_figuras_tabelas.Rmd",
            gpath = "mestrado/artigo_principal/apendices/",
            hide_code = TRUE)
# overwrite the current Rmd with the current google drive 
download_file(file = "secoes_texto/Resultados/Resultados.Rmd",
              gpath = "mestrado/artigo_principal/secoes_texto/")
```


# Texto e tabelas

Todas as análises dos dados foram feitas em R (REF).

## GLMM binomial

Utilizamos funções do pacote lme4 (REF) para ajustar os GLMM binomiais. O modelo com estrutura aleatória mais complexa, com 1 intercepto e 1 inclinação no grau de limitação de dispersão por sítio de amostragem e tipo de paisagem hipotética, teve alerta de não convergência e mesmo depois de ajustar com outros otimizadores o alerta permaneceu. Como era um modelo que demorava muito para ajustar não fiz mais explorações com ele. Outro modelo explorado e descartado foi o modelo cheio que interpretava o grau de limitação de dispersão como variável categórica. Esse modelo demorou muito para rodar e sua execução foi interrompida antes de terminar a estimativa dos coeficientes.
A tabela de seleção, com o delta AICc e peso de evidência, foi obtida usando a função AICctab do pacote bbmle (REF) e os coeficientes de determinação foram obtidos usando a função r.squaredGLMM do pacote MuMIn (REF).
Avaliamos a qualidade de ajuste do modelo explorando os resíduos quantílicos (FIGURA A2 REF) usados no pacote DHARMa (REF). Também plotamos o predito e o observado (FIGURA A2 REF).

# Figuras 

```{r caption 1}
cap <- "Relação entre preditoras: p ~ forest sucession. Olhar texto principal  para descrição das variáveis"
```
```{r fig-p-k,fig.cap=cap,fig.pos="H"}
df_plot %>% filter(k==0.05) %>% distinct() %>% 
  ggplot(aes(x=forest_succession,y=p)) +
  geom_boxplot() +
  geom_jitter() +
  labs(x="forest succession")
```

```{r caption 2}
cap <- "Gráficos diagnósticos"
```
```{r fig-DHARMaResidual,fig.cap=cap,fig.pos="H"}
oname <- load(file="./dados/Rdata/glmm_nCong_selecionado.Rdata",verbose = TRUE)
l_md_e_start <- get(oname)
p_plot <- simulateResiduals(l_md_e_start$modelo,n = 1000)
plot(p_plot)
```

```{r caption 3}
cap <- "Observado e predito para o número de SADs simuladas congruentes com a SAD observada."
```
```{r fig-preditoObs,fig.cap=cap,fig.pos="H"}
oname <- load(file="./dados/Rdata/glmm_nCong_selecionado.Rdata",verbose = TRUE)
l_md_e_start <- get(oname)
df_obs <- l_md_e_start$modelo@frame[,-1]
df_obs$nCong <- l_md_e_start$modelo@frame[,1][,1]
df_obs$predito <- predict(l_md_e_start$modelo,type="response")*sum(l_md_e_start$modelo@frame[,1][1,])
df_obs %>% 
  ggplot(aes(x=nCong,y=predito,group=SiteCode)) +
  geom_line(alpha=0.4) +
  geom_point(alpha=0.4) +
  geom_abline(intercept = 0,slope=1,color="red")+
  facet_grid(land_hyp~forest_succession)
```
